{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center style='font-size:150%; color:#4cd4b4'><strong>Demo on QesNLP API Service</strong></center>\n",
    "\n",
    "\n",
    "$-$ latest @08/14/2023;\n",
    "\n",
    "$-$ `QesNLP API beta version`\n",
    "\n",
    "---\n",
    "\n",
    "<br />\n",
    "\n",
    "> This guide notebook walks through how to utilize the <span style='color:#4cd4b4'>*QesNLP*</span> API. At the core of this API is QES's proprietary language model, known as the Generative Fine-tuned Transformer (GFT). GFT is fine-tuned with a vast type of financial text data to better to the unique linguistic patterns and terminologies prevalent in the finance domain. This quant finance  tailor-made language model forms the basis for a broad array of Natural Language Processing (NLP) tasks, ranging from text preprocessing to downstream classification. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "\n",
    "* QES Financial Natural Language Processing - <span style='color:#4cd4b4'>**QesNLP**</span>   - API provides a suite of NLP toolkits with state-of-the-art deep learning language model designed for applications in finance and investment domain.\n",
    "\n",
    "\n",
    "* The QesNLP API service consists of the following four functionality modules.\n",
    "\n",
    "    - <span style='color:#4cd4b4'>**Preprocessing**</span> Module - This module preprocess the raw text input into parsed machine-readable NLP data structure, including tokenization, summarization, entity recognition, and keyphrases identification.\n",
    "\n",
    "    - <span style='color:#4cd4b4'>**Embedding**</span> Module - This module embed the input text document/sentence into contextual vectors based on the NLP pre-trained language models. The contextualized vectors fit in with the standard machine learning algorithms and could empower the downstream NLP tasks.\n",
    "       \n",
    "    - <span style='color:#4cd4b4'>**Exposure**</span> Module - This module renders the thematic distance between text document to well-defined theme by leveraging the contextual embeddings of both text documents and theme clusters. \n",
    "\n",
    "    - <span style='color:#4cd4b4'>**Classification**</span> Module - This module supports downstream NLP classification tasks, such as sentiment analysis.\n",
    "    \n",
    "* ⚠️ Like conventional Machine Learning algorithm, the GFT language model can still generate noisy outputs which might be incorrect. However, on average, it exhibits superior accuracy compared to traditional bag-of-words methods and could add incremental value on Financial NLP tasks. Moreover, we are dedicated to keep iterating the model to improve the capability in the forthcoming generations. \n",
    "\n",
    "* Please contact Luo.Qes@wolferesearch.com if you have further questions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Usage Demo \n",
    "\n",
    "**Test Input**: A list of financial texts.\n",
    "\n",
    "Here, we extract the following 7 texts from real world as input documents:\n",
    "\n",
    "- Investors thought Wendy’s 15.5% 2022 restaurant-margin target was somewhat conservative.\n",
    "\n",
    "- We expect solid results from DASH. Nice beat/strong guide should be rewarded but upside is likely to balanced given high expectations.\n",
    "\n",
    "- Technicals and incremental news flow will likely continue to drive trading through year end. We wouldn’t be surprised to see some more near-term upside, including the SPX trading into the 4050-4100 range.\n",
    "\n",
    "- While the moves across markets were epic, we believe that our intermediate-term bearish base case remains intact. This includes core inflation remaining very persistent, the Fed hiking to 5-6%, and a recession hitting in 2023.\n",
    "\n",
    "- We believe that earnings and guidance are likely to begin to come under pressure in the coming quarters. Our sense is that companies beating on the top- and bottom-lines and providing constructive outlooks should have an increased chance of outperforming their peers in the months ahead.\n",
    "            \n",
    "- Our business in China market will likely to benefit with the China reopening and recovery scenario.\n",
    "            \n",
    "- To better meet the business development requirement, we have accelerated the application of our Fintech. As we have already introduced like AI and blockchain and all the other advanced technology, we have made a lot of explorations and applications in AI and achieved a lot of outcome in empowering our business."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements and Presteps\n",
    "\n",
    "1. Copy pyqes [python file]( https://github.com/wolferesearch/docs/tree/master/micro-services/api/python/pyqes) from github to your local directory from Github. \n",
    "2. Ensure you have [Pandas](https://pandas.pydata.org/) and [requests](https://pypi.org/project/requests/) package in your python kernel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication and Connection\n",
    "\n",
    "The API is protected using Username and Password. In case you have not received it, please [email](mailto:luo.qes@wolferesearch.com) to apply for API account. \n",
    "\n",
    "The connection object is the gateway to accessing the API. It allows you to access the catalog, portfolios, templates, risk models etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyqes import conn\n",
    "from pyqes import nlp\n",
    "\n",
    "connection = conn.Connection(username = 'xxx',\n",
    "                             password = 'xxx',\n",
    "                             URL = 'http://feed.luoquant.com/nlp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the prestored test inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Investors thought Wendy’s 15.5% 2022 restaurant-margin target was somewhat conservative.', 'We expect solid results from DASH. Nice beat/strong guide should be rewarded but upside is likely to balanced given high expectations.', 'Technicals and incremental news flow will likely continue to drive trading through year end. We wouldn’t be surprised to see some more near-term upside, including the SPX trading into the 4050-4100 range.', 'While the moves across markets were epic, we believe that our intermediate-term bearish base case remains intact. This includes core inflation remaining very persistent, the Fed hiking to 5-6%, and a recession hitting in 2023.', 'We believe that earnings and guidance are likely to begin to come under pressure in the coming quarters. Our sense is that companies beating on the top- and bottom-lines and providing constructive outlooks should have an increased chance of outperforming their peers in the months ahead.', 'Our business in global market will likely to benefit with the China opening and economy recovery scenario.', 'To better meet the business development requirement, we have accelerated the application of our Fintech. As we have already introduced like AI and blockchain and all the other advanced technology, we have made a lot of explorations and applications in AI and achieved a lot of outcome in empowering our business.']\n"
     ]
    }
   ],
   "source": [
    "# specify the input\n",
    "texts = nlp.TEST_DATA_SET['SAMPLE1']\n",
    "\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch <span style='color:#4cd4b4'>**API Class**</span> `nlp.NLPApi` to interact with all NLP Service. Initiate a singleton using the authorized connection object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_api = nlp.NLPApi(connection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## a. QesNLP/preprocessing \n",
    "\n",
    "Preprocessing Module preprocess the raw text input into parsed machine-readable NLP data structure, including tokenization, summarization, entity recognition, and keyphrases identification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyphrases / Keyentities Extraction\n",
    "\n",
    "> The phrase extraction function `.get_key_entity` extracts the diverse keyterms - n-gram - from the given input text. \n",
    "\n",
    "The output of this function is a tuple, which consists of two elements - the identified key terms and a corresponding similarity score. The similarity score ranges between 0 and 1, with a higher value signifying a stronger association between the key term and the input text. In other words, a score closer to 1 indicates that the extracted key term is highly relevant or related to the context of the input text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['wendy', 0.3962],\n",
       "  ['investors', 0.3838],\n",
       "  ['margin target', 0.3514],\n",
       "  ['restaurant', 0.2262]],\n",
       " [['dash', 0.5709],\n",
       "  ['strong guide', 0.4556],\n",
       "  ['solid results', 0.3868],\n",
       "  ['high expectations', 0.2787],\n",
       "  ['nice beat', 0.2667]],\n",
       " [['spx trading', 0.6201],\n",
       "  ['term upside', 0.3451],\n",
       "  ['year end', 0.3164],\n",
       "  ['technicals', 0.277],\n",
       "  ['incremental news flow', 0.2255]],\n",
       " [['core inflation', 0.4825],\n",
       "  ['recession', 0.4425],\n",
       "  ['bearish base case', 0.3862],\n",
       "  ['fed hiking', 0.2564],\n",
       "  ['moves', 0.1843]],\n",
       " [['pressure', 0.3416],\n",
       "  ['earnings', 0.3207],\n",
       "  ['guidance', 0.2984],\n",
       "  ['constructive outlooks', 0.1991],\n",
       "  ['months', 0.0872]],\n",
       " [['economy recovery scenario', 0.5808],\n",
       "  ['global market', 0.5643],\n",
       "  ['china opening', 0.4717],\n",
       "  ['business', 0.4133]],\n",
       " [['fintech', 0.6401],\n",
       "  ['blockchain', 0.4081],\n",
       "  ['business development requirement', 0.4076],\n",
       "  ['ai', 0.3902],\n",
       "  ['applications', 0.3491]]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_api.get_key_entity(list_of_texts = texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['investors thought wendy', 0.6327],\n",
       "  ['target somewhat conservative', 0.5881],\n",
       "  ['wendy restaurant', 0.4744],\n",
       "  ['restaurant margin', 0.3445],\n",
       "  ['somewhat', 0.1834]],\n",
       " [['results dash nice', 0.6862],\n",
       "  ['guide rewarded upside', 0.5599],\n",
       "  ['beat strong guide', 0.5354],\n",
       "  ['upside likely balanced', 0.4375],\n",
       "  ['expect solid', 0.3584]],\n",
       " [['spx trading range', 0.6345],\n",
       "  ['near term upside', 0.4735],\n",
       "  ['drive trading year', 0.4587],\n",
       "  ['technicals incremental', 0.3033],\n",
       "  ['news flow likely', 0.2848]],\n",
       " [['inflation remaining persistent', 0.6236],\n",
       "  ['fed hiking recession', 0.4765],\n",
       "  ['bearish base case', 0.3862],\n",
       "  ['moves markets epic', 0.3566],\n",
       "  ['remains intact includes', 0.3407]],\n",
       " [['earnings guidance likely', 0.6213],\n",
       "  ['pressure coming quarters', 0.5514],\n",
       "  ['companies beating lines', 0.3351],\n",
       "  ['months ahead', 0.3119],\n",
       "  ['outperforming peers', 0.2935]],\n",
       " [['benefit china opening', 0.6663],\n",
       "  ['business global market', 0.6427],\n",
       "  ['economy recovery scenario', 0.5808],\n",
       "  ['market likely benefit', 0.5675],\n",
       "  ['opening economy', 0.5178]],\n",
       " [['application fintech introduced', 0.72],\n",
       "  ['ai blockchain advanced', 0.5724],\n",
       "  ['applications ai achieved', 0.5444],\n",
       "  ['development requirement accelerated', 0.3682],\n",
       "  ['empowering business', 0.3608]]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_api.get_key_phrases(list_of_texts = texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization\n",
    "\n",
    "The Summarization API `summarize` is a powerful tool that distills the essential content from a provided input text and returns a succinct summary. This API is capable of handling batch-level summarization tasks, allowing it to process multiple inputs concurrently with computational efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'Investors thought Wendy’s 15.5% 2022 restaurant-margin target was somewhat conservative.',\n",
       " '1': 'We expect solid results from DASH. Nice beat/strong guide should be rewarded but upside is likely to balanced given high expectations.',\n",
       " '2': 'Technicals and incremental news flow will likely continue to drive trading through year end. We wouldn’t be surprised to see some more near-term upside, including the SPX trading into the 4050-4100 range.',\n",
       " '3': 'We believe that our intermediate-term bearish base case remains intact. This includes core inflation remaining very persistent, the Fed hiking to 5-6%, and a recession hitting in 2023.',\n",
       " '4': 'We believe that earnings and guidance are likely to come under pressure in the coming quarters. Our sense is that companies beating on the top- and bottom-lines and providing constructive outlooks should have an increased chance of outperforming their peers in the months ahead.',\n",
       " '5': 'Our business in global market will likely to benefit with the China opening and economy recovery scenario.',\n",
       " '6': '\"We have accelerated the application of our Fintech. As we have already introduced like AI and blockchain and all the other advanced technology, we have made a lot of explorations and applications in AI,\" he said.'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This may take some time.\n",
    "nlp_api.summarize(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## b. QesNLP/embedding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> QesNLP's financial text embeddings `get_embedding` serve as an advanced tool to quantify the relatedness or similarity between different pieces of text. Essentially, text embeddings are multi-dimensional representations based on the GFT language model, where each text string is transformed into a vector, consisting of a list of floating-point numbers.\n",
    "\n",
    "These embeddings find extensive applications across several domains, including:\n",
    "\n",
    "- Search Functionality: Here, the relevance of the search results is determined based on the degree of similarity to a user's query string, thus optimizing the search results by aligning them closely with the user's intent.\n",
    "\n",
    "- Clustering: Embeddings can be used to cluster or group text strings based on their similarity. This enables easier identification and categorization of related texts, improving data organization and retrieval.\n",
    "\n",
    "- Recommendation Systems: In recommendation engines, items that share similar text strings, and thus similar embeddings, can be recommended to users, enhancing personalization and user experience.\n",
    "\n",
    "- Anomaly Detection: Text embeddings can help identify outliers or anomalies, text strings that exhibit little to no relatedness to a given set of text, thus facilitating better monitoring and error detection.\n",
    "\n",
    "- Diversity Measurement: By analyzing similarity distributions, text embeddings can measure the level of diversity within a given text dataset, providing crucial insights into the range and spread of content.\n",
    "\n",
    "- Text Classification: Text embeddings can be used to assign a class or label to text strings. The classification is based on the similarity of the text to known labels, aiding in automated content classification and tagging.\n",
    "\n",
    "<br/>\n",
    "\n",
    "In terms of relatedness measurement, the 'distance' between two vectors in the multi-dimensional embedding space serves as the metric. A smaller distance between two vectors indicates a high degree of relatedness, suggesting that the text strings are very similar. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `nlp_api.get_embedding` not found.\n"
     ]
    }
   ],
   "source": [
    "nlp_api.get_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.01513153500854969,\n",
       "  -0.022457074373960495,\n",
       "  0.004049981944262981,\n",
       "  0.1051681712269783,\n",
       "  -0.026309631764888763,\n",
       "  0.11871398240327835,\n",
       "  -0.008968377485871315,\n",
       "  -0.12893173098564148,\n",
       "  0.03029773198068142,\n",
       "  0.009070790372788906,\n",
       "  0.06864392757415771,\n",
       "  -0.006944524589926004,\n",
       "  0.07088586688041687,\n",
       "  -0.026452602818608284,\n",
       "  0.02657601423561573,\n",
       "  -0.06798046082258224,\n",
       "  0.017157988622784615,\n",
       "  0.044337280094623566,\n",
       "  0.0027087912894785404,\n",
       "  0.04105174541473389,\n",
       "  -0.04839600995182991,\n",
       "  0.03366716951131821,\n",
       "  0.023741252720355988,\n",
       "  0.0932169184088707,\n",
       "  -0.021327653899788857,\n",
       "  -0.06773635745048523,\n",
       "  -0.01632431335747242,\n",
       "  0.031410448253154755,\n",
       "  -0.0633777379989624,\n",
       "  0.022282054647803307,\n",
       "  -0.0327615812420845,\n",
       "  -0.0686522051692009,\n",
       "  -0.05086243897676468,\n",
       "  0.06490565836429596,\n",
       "  -0.006202189717441797,\n",
       "  0.02210240252315998,\n",
       "  -0.03232797607779503,\n",
       "  -0.042912986129522324,\n",
       "  0.051925577223300934,\n",
       "  -0.030198048800230026,\n",
       "  0.07424700260162354,\n",
       "  0.06149189919233322,\n",
       "  0.010299930348992348,\n",
       "  -0.08049064129590988,\n",
       "  0.03157653659582138,\n",
       "  0.017123768106102943,\n",
       "  -0.056179746985435486,\n",
       "  -0.01786649227142334,\n",
       "  -0.011576179414987564,\n",
       "  0.1196020096540451,\n",
       "  -0.038586512207984924,\n",
       "  -0.00027353482437320054,\n",
       "  0.07415275275707245,\n",
       "  -0.04065866023302078,\n",
       "  0.07864484190940857,\n",
       "  0.008029819466173649,\n",
       "  0.022672679275274277,\n",
       "  -0.07427454739809036,\n",
       "  -0.032532062381505966,\n",
       "  0.024803180247545242,\n",
       "  0.03111725114285946,\n",
       "  0.016324037685990334,\n",
       "  0.05312952771782875,\n",
       "  -0.008623745292425156,\n",
       "  0.03285995125770569,\n",
       "  0.012410108000040054,\n",
       "  -0.029562009498476982,\n",
       "  -0.011394473724067211,\n",
       "  -0.06954428553581238,\n",
       "  0.01368766836822033,\n",
       "  0.012029099278151989,\n",
       "  -0.07046880573034286,\n",
       "  0.023113692179322243,\n",
       "  -0.11741266399621964,\n",
       "  0.012270652689039707,\n",
       "  -0.02672485075891018,\n",
       "  0.03520754724740982,\n",
       "  0.020150797441601753,\n",
       "  -0.033377502113580704,\n",
       "  0.02489347569644451,\n",
       "  0.013906752690672874,\n",
       "  -0.07633448392152786,\n",
       "  -0.05399669334292412,\n",
       "  -0.04083720222115517,\n",
       "  0.007689285557717085,\n",
       "  0.044508080929517746,\n",
       "  -0.0038024201057851315,\n",
       "  0.07524940371513367,\n",
       "  0.068003810942173,\n",
       "  0.05988704413175583,\n",
       "  -0.004557789769023657,\n",
       "  -0.022213611751794815,\n",
       "  -0.02663847990334034,\n",
       "  -0.017546553164720535,\n",
       "  0.0612981878221035,\n",
       "  -0.010646997019648552,\n",
       "  -0.09938358515501022,\n",
       "  -0.08871227502822876,\n",
       "  0.007711331360042095,\n",
       "  -0.02062760479748249,\n",
       "  -0.021719111129641533,\n",
       "  -0.022082161158323288,\n",
       "  0.049737945199012756,\n",
       "  -0.024853909388184547,\n",
       "  0.04067031294107437,\n",
       "  0.005745321977883577,\n",
       "  0.008863248862326145,\n",
       "  0.025200553238391876,\n",
       "  0.07548880577087402,\n",
       "  0.0475936084985733,\n",
       "  0.04521094635128975,\n",
       "  0.07153170555830002,\n",
       "  5.525459710042924e-05,\n",
       "  -0.052275076508522034,\n",
       "  -0.04651714861392975,\n",
       "  0.11397846788167953,\n",
       "  0.05172547698020935,\n",
       "  0.02427670732140541,\n",
       "  0.028161872178316116,\n",
       "  -0.029030440375208855,\n",
       "  0.021199345588684082,\n",
       "  -0.013149281963706017,\n",
       "  -0.023363394662737846,\n",
       "  0.006213120184838772,\n",
       "  -0.11084829270839691,\n",
       "  0.019913319498300552,\n",
       "  -0.0344182588160038,\n",
       "  -0.13499324023723602,\n",
       "  -0.04259326308965683,\n",
       "  -0.047210730612277985,\n",
       "  0.038018397986888885,\n",
       "  -0.03550479933619499,\n",
       "  -0.0027795135974884033,\n",
       "  0.07865854352712631,\n",
       "  0.013780584558844566,\n",
       "  -0.07910890877246857,\n",
       "  0.010909532196819782,\n",
       "  0.0034453640691936016,\n",
       "  0.07168937474489212,\n",
       "  -0.07670421898365021,\n",
       "  -0.10304342955350876,\n",
       "  -0.10408636182546616,\n",
       "  0.0387859046459198,\n",
       "  -0.04859474301338196,\n",
       "  0.007232612930238247,\n",
       "  0.08989036828279495,\n",
       "  -0.03264729678630829,\n",
       "  0.06989067792892456,\n",
       "  -0.00402782903984189,\n",
       "  0.03212517127394676,\n",
       "  0.03489640727639198,\n",
       "  -0.012524435296654701,\n",
       "  -0.07896140962839127,\n",
       "  -0.03884096071124077,\n",
       "  -0.06910032033920288,\n",
       "  0.023143108934164047,\n",
       "  -0.16368061304092407,\n",
       "  0.029227999970316887,\n",
       "  -0.0012083082692697644,\n",
       "  0.012367797084152699,\n",
       "  0.05720902606844902,\n",
       "  -0.05578143149614334,\n",
       "  -0.02785290963947773,\n",
       "  -0.024688923731446266,\n",
       "  0.040460191667079926,\n",
       "  -0.04164036363363266,\n",
       "  0.02683306857943535,\n",
       "  0.001212052651681006,\n",
       "  0.03308245539665222,\n",
       "  -0.042024075984954834,\n",
       "  0.02144390344619751,\n",
       "  0.07056602090597153,\n",
       "  -0.060437120497226715,\n",
       "  0.0458330363035202,\n",
       "  -0.03159264475107193,\n",
       "  0.00534534128382802,\n",
       "  0.019907377660274506,\n",
       "  0.015705900266766548,\n",
       "  0.012614757753908634,\n",
       "  -0.0724133849143982,\n",
       "  -0.05272166058421135,\n",
       "  0.02071918547153473,\n",
       "  -0.0028534657321870327,\n",
       "  -0.07156429439783096,\n",
       "  0.139546737074852,\n",
       "  -0.03211125358939171,\n",
       "  0.03967001661658287,\n",
       "  0.032772477716207504,\n",
       "  -0.07109888643026352,\n",
       "  -0.03503509238362312,\n",
       "  0.07369852811098099,\n",
       "  -0.13505327701568604,\n",
       "  0.04724934324622154,\n",
       "  0.041762981563806534,\n",
       "  -0.04412859305739403,\n",
       "  0.005739815533161163,\n",
       "  0.02477320469915867,\n",
       "  0.06014132499694824,\n",
       "  0.02587825246155262,\n",
       "  -0.11814165115356445,\n",
       "  0.0036262674257159233,\n",
       "  -0.08054293692111969,\n",
       "  -0.02671176940202713,\n",
       "  -0.05262652039527893,\n",
       "  0.07511752843856812,\n",
       "  -0.024462513625621796,\n",
       "  0.038711536675691605,\n",
       "  0.0003316714719403535,\n",
       "  0.07854751497507095,\n",
       "  0.005200348794460297,\n",
       "  0.01903415285050869,\n",
       "  0.03900759294629097,\n",
       "  -0.04545407369732857,\n",
       "  -0.024118460714817047,\n",
       "  0.05959254130721092,\n",
       "  0.011303624138236046,\n",
       "  0.0327887237071991,\n",
       "  -0.03845880180597305,\n",
       "  0.02972486801445484,\n",
       "  0.058632031083106995,\n",
       "  0.05822238326072693,\n",
       "  0.03247157856822014,\n",
       "  -0.02541750855743885,\n",
       "  -2.1159606811304738e-43,\n",
       "  0.05851861461997032,\n",
       "  -0.007413176819682121,\n",
       "  0.025121990591287613,\n",
       "  0.047530222684144974,\n",
       "  0.015109946951270103,\n",
       "  -0.0913967415690422,\n",
       "  0.019839664921164513,\n",
       "  -0.04831825569272041,\n",
       "  -0.04702754318714142,\n",
       "  0.01541740819811821,\n",
       "  -0.04190252721309662,\n",
       "  0.0788443461060524,\n",
       "  -0.024496885016560555,\n",
       "  0.019271841272711754,\n",
       "  -0.05720169469714165,\n",
       "  0.06698816269636154,\n",
       "  0.0005966617027297616,\n",
       "  -0.02510916255414486,\n",
       "  0.031823452562093735,\n",
       "  -0.034548982977867126,\n",
       "  0.015342529863119125,\n",
       "  -0.12991449236869812,\n",
       "  -0.04971689358353615,\n",
       "  0.03254735842347145,\n",
       "  0.006658258847892284,\n",
       "  -0.031311359256505966,\n",
       "  0.029066067188978195,\n",
       "  0.021496031433343887,\n",
       "  -0.05712961032986641,\n",
       "  -0.01651153713464737,\n",
       "  -0.06218016892671585,\n",
       "  -0.013122319243848324,\n",
       "  0.07056554406881332,\n",
       "  -0.08841389417648315,\n",
       "  -0.10512752085924149,\n",
       "  -0.028869474306702614,\n",
       "  -0.01992165856063366,\n",
       "  0.07900730520486832,\n",
       "  0.06073912978172302,\n",
       "  -0.015719875693321228,\n",
       "  0.05529601126909256,\n",
       "  -0.009066582657396793,\n",
       "  -0.02117164060473442,\n",
       "  0.013889364898204803,\n",
       "  -0.010824242606759071,\n",
       "  -0.00909203290939331,\n",
       "  0.07347676903009415,\n",
       "  -0.11579760164022446,\n",
       "  0.05261381343007088,\n",
       "  -0.0236393753439188,\n",
       "  0.02164430543780327,\n",
       "  -0.017343716695904732,\n",
       "  -0.04633320868015289,\n",
       "  -0.008771729655563831,\n",
       "  -0.025885699316859245,\n",
       "  -0.058216385543346405,\n",
       "  -0.023187946528196335,\n",
       "  0.028216002508997917,\n",
       "  0.050451911985874176,\n",
       "  -0.036141786724328995,\n",
       "  -0.10359485447406769,\n",
       "  -0.0040315850637853146,\n",
       "  -0.0674394741654396,\n",
       "  0.012167454697191715,\n",
       "  -0.03663656860589981,\n",
       "  0.022234229370951653,\n",
       "  -0.005177040118724108,\n",
       "  -8.381757652387023e-05,\n",
       "  0.019093437120318413,\n",
       "  -0.04554298520088196,\n",
       "  0.007163418922573328,\n",
       "  0.06382104009389877,\n",
       "  0.13169299066066742,\n",
       "  0.0999753475189209,\n",
       "  -0.0481049120426178,\n",
       "  0.005474799778312445,\n",
       "  0.12168502807617188,\n",
       "  0.01330833975225687,\n",
       "  -0.04163385555148125,\n",
       "  0.01708063669502735,\n",
       "  0.004634586162865162,\n",
       "  0.013693351298570633,\n",
       "  -0.06221863254904747,\n",
       "  -0.0565357469022274,\n",
       "  -0.007244833279401064,\n",
       "  0.002852586330845952,\n",
       "  0.031716685742139816,\n",
       "  0.021979305893182755,\n",
       "  -0.016176331788301468,\n",
       "  0.0022015648428350687,\n",
       "  -0.0138526177033782,\n",
       "  0.0063586151227355,\n",
       "  0.0049522980116307735,\n",
       "  0.028009187430143356,\n",
       "  0.08536667376756668,\n",
       "  2.1706113212391416e-42,\n",
       "  -0.002835162216797471,\n",
       "  -0.07362083345651627,\n",
       "  0.03591134399175644,\n",
       "  0.05139406770467758,\n",
       "  -0.03355279192328453,\n",
       "  0.022793017327785492,\n",
       "  -0.06299033015966415,\n",
       "  -0.13974906504154205,\n",
       "  0.018875695765018463,\n",
       "  0.00431187404319644,\n",
       "  0.027189696207642555,\n",
       "  0.056029923260211945,\n",
       "  -0.004458641167730093,\n",
       "  -0.040487419813871384,\n",
       "  -0.01339817326515913,\n",
       "  -0.04448665678501129,\n",
       "  0.04605277255177498,\n",
       "  -0.027996279299259186,\n",
       "  -0.01444949209690094,\n",
       "  0.0820557177066803,\n",
       "  0.05659155920147896,\n",
       "  -0.03815329447388649,\n",
       "  -0.045038413256406784,\n",
       "  -0.05198734998703003,\n",
       "  -0.013138042762875557,\n",
       "  0.06679578125476837,\n",
       "  -0.040419675409793854,\n",
       "  0.09419926255941391,\n",
       "  -0.06281125545501709,\n",
       "  -0.07787482440471649,\n",
       "  -0.04342064633965492,\n",
       "  -0.08148060739040375,\n",
       "  -0.033171940594911575,\n",
       "  0.05325399339199066,\n",
       "  -0.001497397548519075,\n",
       "  -0.04863928630948067,\n",
       "  -0.0671008750796318,\n",
       "  -0.028492718935012817,\n",
       "  -0.04280748963356018,\n",
       "  -0.03739894554018974,\n",
       "  -0.05844767019152641,\n",
       "  -0.004331163130700588,\n",
       "  -0.030315760523080826,\n",
       "  0.004138517193496227,\n",
       "  -0.002480490365996957,\n",
       "  0.01749059557914734,\n",
       "  0.03690561279654503,\n",
       "  0.012015254236757755,\n",
       "  -0.0026025280822068453,\n",
       "  0.01320403628051281,\n",
       "  0.002632784191519022,\n",
       "  0.04666982963681221,\n",
       "  -0.06656835228204727,\n",
       "  -0.05637435242533684,\n",
       "  -0.0887787714600563,\n",
       "  0.07236799597740173,\n",
       "  0.10497193038463593,\n",
       "  0.04854553937911987,\n",
       "  -0.05248074606060982,\n",
       "  -0.0005859583616256714,\n",
       "  0.02221796289086342,\n",
       "  0.029503576457500458,\n",
       "  -0.07961632311344147,\n",
       "  -0.01954181119799614],\n",
       " [-0.11030566692352295,\n",
       "  0.048130009323358536,\n",
       "  -0.028756380081176758,\n",
       "  -0.09290950000286102,\n",
       "  -0.07872889190912247,\n",
       "  -0.003755199024453759,\n",
       "  -0.036646414548158646,\n",
       "  -0.0012601637281477451,\n",
       "  -0.06656556576490402,\n",
       "  0.0011649266816675663,\n",
       "  -0.020022233948111534,\n",
       "  0.023972688242793083,\n",
       "  0.04728851094841957,\n",
       "  0.09171760082244873,\n",
       "  0.04032250866293907,\n",
       "  0.04368346184492111,\n",
       "  0.04388713091611862,\n",
       "  0.08605504781007767,\n",
       "  -0.009690433740615845,\n",
       "  -0.061108916997909546,\n",
       "  -0.0667964294552803,\n",
       "  -0.0581950806081295,\n",
       "  0.02246653474867344,\n",
       "  -0.04375782981514931,\n",
       "  -0.09119996428489685,\n",
       "  0.04890870302915573,\n",
       "  -0.04767467826604843,\n",
       "  0.014045994728803635,\n",
       "  0.005466266069561243,\n",
       "  -0.00953626073896885,\n",
       "  0.009035424329340458,\n",
       "  -0.05747925862669945,\n",
       "  0.031063048169016838,\n",
       "  0.0021979399025440216,\n",
       "  -0.04981551691889763,\n",
       "  -0.013100756332278252,\n",
       "  -0.06601005792617798,\n",
       "  0.01583775505423546,\n",
       "  -0.06719333678483963,\n",
       "  -0.08502428978681564,\n",
       "  0.023478731513023376,\n",
       "  0.011565793305635452,\n",
       "  -0.07437305152416229,\n",
       "  -0.04502234235405922,\n",
       "  -0.04537583887577057,\n",
       "  -0.04709272459149361,\n",
       "  -0.06655149906873703,\n",
       "  0.011103973723948002,\n",
       "  -0.00918173510581255,\n",
       "  0.016455132514238358,\n",
       "  0.053823016583919525,\n",
       "  0.04295750707387924,\n",
       "  -0.018696574494242668,\n",
       "  0.00031117795151658356,\n",
       "  -0.0607605017721653,\n",
       "  -0.012439025565981865,\n",
       "  0.017985140904784203,\n",
       "  0.00265110214240849,\n",
       "  -0.06237279623746872,\n",
       "  0.06936570256948471,\n",
       "  0.002422679215669632,\n",
       "  0.011147188022732735,\n",
       "  -0.04461904987692833,\n",
       "  -0.014592651277780533,\n",
       "  0.09530086070299149,\n",
       "  0.0076324050314724445,\n",
       "  -0.07468858361244202,\n",
       "  -0.08450184762477875,\n",
       "  0.00870945118367672,\n",
       "  0.026421012356877327,\n",
       "  -0.029788076877593994,\n",
       "  0.0030230737756937742,\n",
       "  0.026008237153291702,\n",
       "  -0.06162071228027344,\n",
       "  0.017701322212815285,\n",
       "  0.0026685039047151804,\n",
       "  -0.03246684744954109,\n",
       "  -0.02915690466761589,\n",
       "  -0.029091469943523407,\n",
       "  0.02178020402789116,\n",
       "  0.015769686549901962,\n",
       "  -0.043135371059179306,\n",
       "  -0.02663915604352951,\n",
       "  0.0276371780782938,\n",
       "  0.027630474418401718,\n",
       "  0.004401387646794319,\n",
       "  0.023541312664747238,\n",
       "  0.045918673276901245,\n",
       "  -0.037764184176921844,\n",
       "  0.11126349866390228,\n",
       "  0.0669650137424469,\n",
       "  -0.04717424511909485,\n",
       "  -0.03936133533716202,\n",
       "  -0.05318316072225571,\n",
       "  -0.01163677591830492,\n",
       "  0.11556874215602875,\n",
       "  -0.057210829108953476,\n",
       "  0.001139884116128087,\n",
       "  -0.006401063874363899,\n",
       "  0.024192258715629578,\n",
       "  -0.023208050057291985,\n",
       "  -0.054968371987342834,\n",
       "  0.05120036005973816,\n",
       "  -0.026896091178059578,\n",
       "  0.005487026646733284,\n",
       "  -0.06285994499921799,\n",
       "  0.04006626829504967,\n",
       "  -0.020947132259607315,\n",
       "  -0.004646516405045986,\n",
       "  -0.030046992003917694,\n",
       "  -0.0011573081137612462,\n",
       "  -0.04176492616534233,\n",
       "  -0.0504528284072876,\n",
       "  -0.03329996392130852,\n",
       "  -0.04079761356115341,\n",
       "  0.001320685725659132,\n",
       "  -0.08156736195087433,\n",
       "  0.07771383970975876,\n",
       "  0.07042960822582245,\n",
       "  0.042384713888168335,\n",
       "  -0.0027983703184872866,\n",
       "  -0.027551013976335526,\n",
       "  0.017602646723389626,\n",
       "  0.016257384791970253,\n",
       "  0.05776873603463173,\n",
       "  0.07800564914941788,\n",
       "  -0.0061636799946427345,\n",
       "  -0.03750701621174812,\n",
       "  -0.052022241055965424,\n",
       "  0.021516598761081696,\n",
       "  0.1037931963801384,\n",
       "  -0.01773114874958992,\n",
       "  0.01234224159270525,\n",
       "  0.033460624516010284,\n",
       "  0.0192410871386528,\n",
       "  -0.058728206902742386,\n",
       "  0.054779887199401855,\n",
       "  0.08575333654880524,\n",
       "  0.06569445878267288,\n",
       "  0.06433872133493423,\n",
       "  -0.010122351348400116,\n",
       "  0.0255855955183506,\n",
       "  -0.057545166462659836,\n",
       "  0.07289803773164749,\n",
       "  0.014018075540661812,\n",
       "  -0.056423038244247437,\n",
       "  -0.0012552683474496007,\n",
       "  -0.022948037832975388,\n",
       "  0.06152368709445,\n",
       "  -0.023823697119951248,\n",
       "  0.029493169859051704,\n",
       "  -0.09554032236337662,\n",
       "  0.0184239000082016,\n",
       "  0.007691608741879463,\n",
       "  -0.022631198167800903,\n",
       "  -0.005294859409332275,\n",
       "  -0.01775694452226162,\n",
       "  0.0955362468957901,\n",
       "  0.1079542264342308,\n",
       "  -0.043870165944099426,\n",
       "  -0.01714157871901989,\n",
       "  -0.04594631493091583,\n",
       "  -0.005300424061715603,\n",
       "  -0.05229759216308594,\n",
       "  -0.07149910181760788,\n",
       "  0.032180096954107285,\n",
       "  -0.052401103079319,\n",
       "  -0.015043080784380436,\n",
       "  0.01055467315018177,\n",
       "  0.07434298098087311,\n",
       "  -0.016626503318548203,\n",
       "  -0.011299327947199345,\n",
       "  -0.022393696010112762,\n",
       "  0.01856006681919098,\n",
       "  0.03967404365539551,\n",
       "  -0.04416123032569885,\n",
       "  -0.013403558172285557,\n",
       "  -0.07985412329435349,\n",
       "  -0.01030402909964323,\n",
       "  -0.04355703666806221,\n",
       "  0.07537258416414261,\n",
       "  0.009102901443839073,\n",
       "  0.037221603095531464,\n",
       "  0.039768099784851074,\n",
       "  0.0010378423612564802,\n",
       "  0.07496783882379532,\n",
       "  -0.07765033841133118,\n",
       "  -0.019116897135972977,\n",
       "  0.08624812960624695,\n",
       "  0.009773194789886475,\n",
       "  0.05288071930408478,\n",
       "  -0.11697643995285034,\n",
       "  -0.05448255315423012,\n",
       "  -0.0033905331511050463,\n",
       "  0.015849744901061058,\n",
       "  -0.01935555227100849,\n",
       "  -0.06346092373132706,\n",
       "  0.0025967080146074295,\n",
       "  -0.06736188381910324,\n",
       "  -0.01883012428879738,\n",
       "  -0.05540084466338158,\n",
       "  0.03276875987648964,\n",
       "  0.11960551887750626,\n",
       "  0.053511399775743484,\n",
       "  0.06286811828613281,\n",
       "  0.032580506056547165,\n",
       "  0.05182167887687683,\n",
       "  0.022701064124703407,\n",
       "  0.020297741517424583,\n",
       "  0.13057778775691986,\n",
       "  -0.02832341007888317,\n",
       "  -0.0196940079331398,\n",
       "  -0.0010672762291505933,\n",
       "  0.011978021822869778,\n",
       "  0.004630593582987785,\n",
       "  -0.11486900597810745,\n",
       "  -0.06828632205724716,\n",
       "  -0.08483454585075378,\n",
       "  0.06943771243095398,\n",
       "  0.03437510132789612,\n",
       "  -0.05467735230922699,\n",
       "  -0.013896821066737175,\n",
       "  -0.057011425495147705,\n",
       "  5.423025056937042e-43,\n",
       "  0.027606140822172165,\n",
       "  -0.09207772463560104,\n",
       "  0.0035752493422478437,\n",
       "  -0.008836371824145317,\n",
       "  0.015605064108967781,\n",
       "  0.007039759308099747,\n",
       "  0.037224091589450836,\n",
       "  0.004203341901302338,\n",
       "  0.03648190572857857,\n",
       "  0.048239704221487045,\n",
       "  -0.08709049224853516,\n",
       "  0.023536454886198044,\n",
       "  -0.02043318934738636,\n",
       "  0.05515338107943535,\n",
       "  0.043973106890916824,\n",
       "  -0.06233630329370499,\n",
       "  -0.0115917157381773,\n",
       "  -0.07297351956367493,\n",
       "  0.062381960451602936,\n",
       "  -0.00817814003676176,\n",
       "  -0.037026021629571915,\n",
       "  0.010895805433392525,\n",
       "  0.014446851797401905,\n",
       "  -0.09553848206996918,\n",
       "  -0.001971917925402522,\n",
       "  -0.09819696098566055,\n",
       "  0.0763610377907753,\n",
       "  -0.013154628686606884,\n",
       "  0.022636841982603073,\n",
       "  0.013878097757697105,\n",
       "  -0.014963281340897083,\n",
       "  0.06633936613798141,\n",
       "  -0.0071750665083527565,\n",
       "  0.014335323125123978,\n",
       "  0.020489275455474854,\n",
       "  0.01264382153749466,\n",
       "  -0.05972246825695038,\n",
       "  -0.09512364864349365,\n",
       "  -0.003794026328250766,\n",
       "  0.03409336879849434,\n",
       "  0.0023868209682404995,\n",
       "  0.002040646504610777,\n",
       "  0.10308241844177246,\n",
       "  -0.06503619253635406,\n",
       "  -0.00574029004201293,\n",
       "  -0.008470488712191582,\n",
       "  -0.10862752795219421,\n",
       "  0.060037627816200256,\n",
       "  -0.07016999274492264,\n",
       "  -0.013561123982071877,\n",
       "  0.01497579924762249,\n",
       "  -0.041185565292835236,\n",
       "  0.002662842394784093,\n",
       "  0.035908591002225876,\n",
       "  0.0854518935084343,\n",
       "  -0.028818117454648018,\n",
       "  -0.06102775037288666,\n",
       "  -0.009924573823809624,\n",
       "  -0.01372014731168747,\n",
       "  0.06342971324920654,\n",
       "  0.006645514164119959,\n",
       "  0.08022096008062363,\n",
       "  -0.03641116991639137,\n",
       "  -0.03654703125357628,\n",
       "  0.0147926714271307,\n",
       "  0.01595539227128029,\n",
       "  -0.0200049951672554,\n",
       "  -0.01797676831483841,\n",
       "  0.003955595660954714,\n",
       "  0.045369748026132584,\n",
       "  0.019379502162337303,\n",
       "  0.10508189350366592,\n",
       "  0.0494377426803112,\n",
       "  0.01623718999326229,\n",
       "  0.03759250044822693,\n",
       "  0.01429130882024765,\n",
       "  0.011084242723882198,\n",
       "  0.02693122811615467,\n",
       "  0.14448422193527222,\n",
       "  -0.02690001390874386,\n",
       "  -0.008535578846931458,\n",
       "  0.046238165348768234,\n",
       "  -0.022058945149183273,\n",
       "  0.009509600698947906,\n",
       "  0.056969404220581055,\n",
       "  0.03415369987487793,\n",
       "  -0.04582435265183449,\n",
       "  0.09507223963737488,\n",
       "  -0.0031312669161707163,\n",
       "  -0.0004108332796022296,\n",
       "  0.0444740392267704,\n",
       "  0.038271065801382065,\n",
       "  0.006161466706544161,\n",
       "  -0.0370950810611248,\n",
       "  -0.01997346058487892,\n",
       "  1.9211801945893242e-42,\n",
       "  0.017485039308667183,\n",
       "  -0.0030838565435260534,\n",
       "  0.031056424602866173,\n",
       "  0.11029841750860214,\n",
       "  -0.051722146570682526,\n",
       "  0.09932087361812592,\n",
       "  0.008889819495379925,\n",
       "  -0.10967916995286942,\n",
       "  -0.009082531556487083,\n",
       "  0.00043380161514505744,\n",
       "  0.0025356332771480083,\n",
       "  0.047301966696977615,\n",
       "  -0.06401485949754715,\n",
       "  -0.01304494310170412,\n",
       "  0.020520536229014397,\n",
       "  0.0984942764043808,\n",
       "  0.02351055108010769,\n",
       "  0.09607063233852386,\n",
       "  -0.015070146881043911,\n",
       "  -0.012191087938845158,\n",
       "  -0.07442991435527802,\n",
       "  0.040967319160699844,\n",
       "  -0.007913214154541492,\n",
       "  0.012684603221714497,\n",
       "  0.059755537658929825,\n",
       "  0.008979284204542637,\n",
       "  0.0017165939789265394,\n",
       "  -0.022508220747113228,\n",
       "  -0.016460642218589783,\n",
       "  -0.004899017978459597,\n",
       "  -0.04329637810587883,\n",
       "  -0.060500290244817734,\n",
       "  0.049532219767570496,\n",
       "  -0.06895890831947327,\n",
       "  -0.0023619055282324553,\n",
       "  -0.08509416878223419,\n",
       "  -0.02096412144601345,\n",
       "  -0.03162034973502159,\n",
       "  0.06253524124622345,\n",
       "  0.04695146903395653,\n",
       "  0.0430290512740612,\n",
       "  0.09875185042619705,\n",
       "  -0.056311216205358505,\n",
       "  -0.03202419728040695,\n",
       "  0.03049623966217041,\n",
       "  -0.03928906098008156,\n",
       "  0.16766467690467834,\n",
       "  -0.11296707391738892,\n",
       "  -0.11833536624908447,\n",
       "  -0.027224726974964142,\n",
       "  -0.0013043438084423542,\n",
       "  -0.01728827692568302,\n",
       "  -0.10056988894939423,\n",
       "  -0.01458943635225296,\n",
       "  -0.024632081389427185,\n",
       "  0.054836906492710114,\n",
       "  -0.06966442614793777,\n",
       "  -0.02056802809238434,\n",
       "  0.03278401494026184,\n",
       "  0.06477382779121399,\n",
       "  0.05813819542527199,\n",
       "  0.06203779578208923,\n",
       "  -0.09588120132684708,\n",
       "  0.12230109423398972]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_api.get_embedding(texts)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## c. QesNLP/exposure\n",
    "\n",
    "> The `QesNLP/exposure` module quantifiy the thematic distance between text document to well-defined theme by leveraging the contextual embeddings of both text documents and theme clusters. \n",
    "\n",
    "At the heart of our NLP exposure on theme lies our <span style='color:#4cd4b4'>**ThemeGFT**</span>  – a machine learnt NLP embedding and clustering pipeline empowered by GFT model, used to identify and create themes fine-tuned by humans annotation. \n",
    "\n",
    "<span style='color:#4cd4b4'>**Thematic contextual embeddings**</span> provide a nuanced and powerful way to represent the meaning of words, phrases, and documents within a specific theme or domain. By incorporating contextual information from surrounding words and the overarching theme, these embeddings capture not only the general meaning of words but also the subtle variations in meaning that occur in different thematic contexts. This allows for a more accurate representation of the relationships between text elements, leading to better quality document classification and topics model within the domain. \n",
    "\n",
    "We currently provide specialized suites of fine-tuned ThemeGFT to quantify the contextual exposure from given text document to predefined themes:\n",
    "\n",
    "- `General` offers encompasses 21 core universal themes, ranging from Artificial Intelligence (AI) and Environmental, Social, and Governance (ESG), to Margin.\n",
    "\n",
    "- `China` offers a dedicated themes relevant to China, which is based on our China Reopen thematic research. \n",
    "\n",
    "The exposure score computed by these models varies between 0 and 1, where a score of 1 implies complete semantic exposure to a particular theme. This numerical representation offers a quantifiable measure of the extent to which a document aligns with the defined thematic context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AI</th>\n",
       "      <th>ESG</th>\n",
       "      <th>SupplyChain</th>\n",
       "      <th>Inflation</th>\n",
       "      <th>Tech</th>\n",
       "      <th>HumanCapital</th>\n",
       "      <th>Margin</th>\n",
       "      <th>CashFlow</th>\n",
       "      <th>RevGrowth</th>\n",
       "      <th>Cost</th>\n",
       "      <th>...</th>\n",
       "      <th>Debt</th>\n",
       "      <th>Earnings</th>\n",
       "      <th>Buyback</th>\n",
       "      <th>Dividend</th>\n",
       "      <th>Marketing</th>\n",
       "      <th>GlobalMarket</th>\n",
       "      <th>OperatingPerformance</th>\n",
       "      <th>Tax</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.819087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AI  ESG  SupplyChain  Inflation  Tech  HumanCapital  Margin  CashFlow  \\\n",
       "0  0.0  0.0          0.0   0.000000   0.0           0.0     0.0       0.0   \n",
       "1  0.0  0.0          0.0   0.000000   0.0           0.0     0.0       0.0   \n",
       "2  0.0  0.0          0.0   0.000000   0.0           0.0     0.0       0.0   \n",
       "3  0.0  0.0          0.0   0.819087   0.0           0.0     0.0       0.0   \n",
       "4  0.0  0.0          0.0   0.000000   0.0           0.0     0.0       0.0   \n",
       "5  0.0  0.0          0.0   0.000000   0.0           0.0     0.0       0.0   \n",
       "6  1.0  0.0          0.0   0.000000   1.0           0.0     0.0       0.0   \n",
       "\n",
       "   RevGrowth  Cost  ...  Debt  Earnings  Buyback  Dividend  Marketing  \\\n",
       "0        0.0   0.0  ...   0.0       0.0      0.0       0.0        0.0   \n",
       "1        0.0   0.0  ...   0.0       0.0      0.0       0.0        0.0   \n",
       "2        0.0   0.0  ...   0.0       0.0      0.0       0.0        0.0   \n",
       "3        0.0   0.0  ...   0.0       0.0      0.0       0.0        0.0   \n",
       "4        0.0   0.0  ...   0.0       1.0      0.0       0.0        0.0   \n",
       "5        0.0   0.0  ...   0.0       0.0      0.0       0.0        0.0   \n",
       "6        0.0   0.0  ...   0.0       0.0      0.0       0.0        0.0   \n",
       "\n",
       "   GlobalMarket  OperatingPerformance  Tax  Energy  Demand  \n",
       "0      0.000000                   0.0  0.0     0.0     0.0  \n",
       "1      0.000000                   0.0  0.0     0.0     0.0  \n",
       "2      0.000000                   0.0  0.0     0.0     0.0  \n",
       "3      0.000000                   0.0  0.0     0.0     0.0  \n",
       "4      0.000000                   0.0  0.0     0.0     0.0  \n",
       "5      0.001185                   0.0  0.0     0.0     0.0  \n",
       "6      0.000000                   0.0  0.0     0.0     0.0  \n",
       "\n",
       "[7 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General ThemeGFT model\n",
    "nlp_api.get_general_theme_exposure(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>China/COVID</th>\n",
       "      <th>China/Economy</th>\n",
       "      <th>China/SupplyChain</th>\n",
       "      <th>China/Market&amp;Business</th>\n",
       "      <th>China/SalesGrowth</th>\n",
       "      <th>China/Tariff</th>\n",
       "      <th>China/Invest</th>\n",
       "      <th>China/Reopen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.120171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.761358</td>\n",
       "      <td>0.18679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   China/COVID  China/Economy  China/SupplyChain  China/Market&Business  \\\n",
       "0          0.0            0.0                0.0                    0.0   \n",
       "1          0.0            0.0                0.0                    0.0   \n",
       "2          0.0            0.0                0.0                    0.0   \n",
       "3          0.0            0.0                0.0                    0.0   \n",
       "4          0.0            0.0                0.0                    0.0   \n",
       "5          0.0            1.0                0.0                    1.0   \n",
       "6          0.0            0.0                0.0                    0.0   \n",
       "\n",
       "   China/SalesGrowth  China/Tariff  China/Invest  China/Reopen  \n",
       "0           0.000000           0.0      0.000000       0.00000  \n",
       "1           0.000000           0.0      0.000000       0.00000  \n",
       "2           0.000000           0.0      0.000000       0.00000  \n",
       "3           0.000000           0.0      0.000000       0.00000  \n",
       "4           0.000000           0.0      0.000000       0.00000  \n",
       "5           0.120171           0.0      0.761358       0.18679  \n",
       "6           0.000000           0.0      0.000000       0.00000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ChinaReopen ThemeGFT Model\n",
    "nlp_api.get_china_theme_exposure(texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## d. QesNLP/classification\n",
    "\n",
    ">  The classification module supports downstream NLP financial classification tasks, featuring financial sentiment analysis.\n",
    "\n",
    "**Input**: A financial text.\n",
    "\n",
    "**Argument**: The model type including analyst tone (`analyst-tone`), news sentiment (`news-sentiment`), social media sentiment (`twitter-sentiment`), etc.\n",
    "\n",
    "**Output**: probability with associated label, sum up to one.\n",
    "\n",
    "**Models**: There are 5 fine-tuned NLP classification models available designed for different application domain like financial news or analyst comments. \n",
    "\n",
    "| Model Type/Argument |                                                                                                                                                           Description                                                                                                                                                          |                                    Label                                    |             Notes            |   |\n",
    "|:-------------------:|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:---------------------------------------------------------------------------:|:----------------------------:|---|\n",
    "|     analyst-tone    | FinBERT-analyst-tone model is fine-tuned on 10,000 manually annotated (positive, negative, neutral) sentences from analylst reports. This model achieves superior performance on financial tone anlaysis task.                                                                                                                 | positive, neutral, negative                                                 | the default sentiment engine |   |\n",
    "|    news-sentiment   | FinBERT-news-sentiment model is fine-tuned on 10,000 manually annotated (positive, negative, neutral) sentences from financial news. This model achieves superior performance on financial sentiment anlaysis task.                                                                                                            | positive, neutral, negative                                                 |                              |   |\n",
    "|  twitter-sentiment  | The BERT-twitter model is fine-tuned on trained on ~58M English tweets and fine-tuned for sentiment analysis with the TweetEval benchmark, a unified benchmark for tweet classification consisting of seven heterogeneous tasks that are core to social media NLP research such as Sentiment Analysis and Emotion Recognition. | positive, neutral, negative                                                 |                              |   |\n",
    "|   twitter-emotion   |                                                                                                                                                                                                                                                                                                                                | joy, anger, sadness, optimism                                               |                              |   |\n",
    "|   forward-looking   | Forward-looking statements (FLS) inform investors of managers’ beliefs and opinions about firm's future events or results.                                                                                                                                                                                                     | not forward looking, non-specific forward-looking, specific forward-looking |                              |   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.218236e-01</td>\n",
       "      <td>0.017037</td>\n",
       "      <td>7.611394e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.367909e-09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.229531e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.465640e-02</td>\n",
       "      <td>0.983423</td>\n",
       "      <td>1.920860e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.217681e-06</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.999905e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.961951e-07</td>\n",
       "      <td>0.999311</td>\n",
       "      <td>6.887265e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.992363e-09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.782749e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.308855e-07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.769387e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        neutral  positive      negative\n",
       "0  2.218236e-01  0.017037  7.611394e-01\n",
       "1  4.367909e-09  1.000000  2.229531e-09\n",
       "2  1.465640e-02  0.983423  1.920860e-03\n",
       "3  3.217681e-06  0.000007  9.999905e-01\n",
       "4  5.961951e-07  0.999311  6.887265e-04\n",
       "5  3.992363e-09  1.000000  7.782749e-09\n",
       "6  3.308855e-07  1.000000  1.769387e-07"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generic sentiment identification model \n",
    "nlp_api.compute_sentiment(list_of_texts = texts, model = 'analyst-tone')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Forward-looking tone detection `.compute_forward_looking_tone` : detect if a given text document statement is forward-looking or not. Forward-Looking Statements (FLS) are typically declarations made by company management that convey their beliefs, expectations, or predictions about the company's future events or results.\n",
    "        Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>notFL</th>\n",
       "      <th>nonspecificFL</th>\n",
       "      <th>specificFL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.989592</td>\n",
       "      <td>0.004289</td>\n",
       "      <td>0.006119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.094768</td>\n",
       "      <td>0.355109</td>\n",
       "      <td>0.550124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.024221</td>\n",
       "      <td>0.315546</td>\n",
       "      <td>0.660233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.921976</td>\n",
       "      <td>0.025728</td>\n",
       "      <td>0.052295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.063698</td>\n",
       "      <td>0.388626</td>\n",
       "      <td>0.547676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.009463</td>\n",
       "      <td>0.375107</td>\n",
       "      <td>0.615431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.961722</td>\n",
       "      <td>0.013028</td>\n",
       "      <td>0.025250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      notFL  nonspecificFL  specificFL\n",
       "0  0.989592       0.004289    0.006119\n",
       "1  0.094768       0.355109    0.550124\n",
       "2  0.024221       0.315546    0.660233\n",
       "3  0.921976       0.025728    0.052295\n",
       "4  0.063698       0.388626    0.547676\n",
       "5  0.009463       0.375107    0.615431\n",
       "6  0.961722       0.013028    0.025250"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_api.compute_forward_looking_tone(list_of_texts = texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Social media emotion identification `.compute_social_emotion`: fine-tuned with social media comments allowing it to adeptly discern the underlying emotions conveyed within these interactions. Moreover, it also possesses the ability to comprehend the sentiments expressed through emojis, further enhancing its understanding of nuanced digital communication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>joy</th>\n",
       "      <th>optimism</th>\n",
       "      <th>sadness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012298</td>\n",
       "      <td>0.071588</td>\n",
       "      <td>0.019461</td>\n",
       "      <td>0.896654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.078456</td>\n",
       "      <td>0.771030</td>\n",
       "      <td>0.125856</td>\n",
       "      <td>0.024658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      anger       joy  optimism   sadness\n",
       "0  0.012298  0.071588  0.019461  0.896654\n",
       "1  0.078456  0.771030  0.125856  0.024658"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_api.compute_social_emotion(list_of_texts = ['GME to the moon? 😭',\n",
    "                                                'GME to the moon! 🚀'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
